<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>Reinforcement Learning | Josherich logs</title>
    <meta name="description" content="Josherich logs">
    <link rel="icon" href="/logs/logo.png">
  <link rel="manifest" href="/logs/manifest.json">
  <meta name="theme-color" content="#fff">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <link rel="apple-touch-icon" href="/logs/apple-touch-icon.png">
  <link rel="mask-icon" href="/logs/safari-pinned-tab.svg" color="#ff8549">
    
    <link rel="preload" href="/logs/assets/css/0.styles.7191ec3a.css" as="style"><link rel="preload" href="/logs/assets/js/app.09a71387.js" as="script"><link rel="preload" href="/logs/assets/js/2.5fba0fc3.js" as="script"><link rel="preload" href="/logs/assets/js/8.1099fc02.js" as="script"><link rel="prefetch" href="/logs/assets/js/10.d006e7a8.js"><link rel="prefetch" href="/logs/assets/js/11.fd749eab.js"><link rel="prefetch" href="/logs/assets/js/12.e197d713.js"><link rel="prefetch" href="/logs/assets/js/13.5faee3eb.js"><link rel="prefetch" href="/logs/assets/js/14.dd1edca1.js"><link rel="prefetch" href="/logs/assets/js/15.8ccfa7a9.js"><link rel="prefetch" href="/logs/assets/js/16.0254efc1.js"><link rel="prefetch" href="/logs/assets/js/17.e177a4da.js"><link rel="prefetch" href="/logs/assets/js/18.1cf5c84a.js"><link rel="prefetch" href="/logs/assets/js/19.0a4d2d26.js"><link rel="prefetch" href="/logs/assets/js/20.6ad277bf.js"><link rel="prefetch" href="/logs/assets/js/21.f653a922.js"><link rel="prefetch" href="/logs/assets/js/22.d66a1538.js"><link rel="prefetch" href="/logs/assets/js/23.c2b61054.js"><link rel="prefetch" href="/logs/assets/js/24.a688e03c.js"><link rel="prefetch" href="/logs/assets/js/25.ce0b2b01.js"><link rel="prefetch" href="/logs/assets/js/26.98393859.js"><link rel="prefetch" href="/logs/assets/js/27.9c56208f.js"><link rel="prefetch" href="/logs/assets/js/28.2b361e5f.js"><link rel="prefetch" href="/logs/assets/js/3.e79b47f3.js"><link rel="prefetch" href="/logs/assets/js/4.824b2f94.js"><link rel="prefetch" href="/logs/assets/js/5.cf7ef866.js"><link rel="prefetch" href="/logs/assets/js/6.d8e82984.js"><link rel="prefetch" href="/logs/assets/js/7.99d61cc4.js"><link rel="prefetch" href="/logs/assets/js/9.64f7f7fe.js">
    <link rel="stylesheet" href="/logs/assets/css/0.styles.7191ec3a.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/logs/" class="home-link router-link-active"><!----> <span class="site-name">Josherich logs</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/logs/" class="nav-link">Home</a></div> <a href="https://github.com/josherich/blog" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/logs/" class="nav-link">Home</a></div> <a href="https://github.com/josherich/blog" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Home</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>Logs</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/logs/logs.html" class="sidebar-link">Logs</a></li><li><a href="/logs/cloud.html" class="sidebar-link">cloud</a></li><li><a href="/logs/cpp.html" class="sidebar-link">CPP</a></li><li><a href="/logs/cs.html" class="sidebar-link">CS</a></li><li><a href="/logs/database.html" class="sidebar-link">Database</a></li><li><a href="/logs/draw.html" class="sidebar-link">Draw</a></li><li><a href="/logs/frontend.html" class="sidebar-link">Front end</a></li><li><a href="/logs/gaming.html" class="sidebar-link">Books</a></li><li><a href="/logs/josherich.html" class="sidebar-link">Josherich</a></li><li><a href="/logs/languages.html" class="sidebar-link">Language</a></li><li><a href="/logs/math.html" class="sidebar-link">Math</a></li><li><a href="/logs/ml.html" class="sidebar-link">Machine Learning</a></li><li><a href="/logs/nlp.html" class="sidebar-link">NLP</a></li><li><a href="/logs/numpy.html" class="sidebar-link">Numpy</a></li><li><a href="/logs/ops.html" class="sidebar-link">Ops</a></li><li><a href="/logs/os.html" class="sidebar-link">OS</a></li><li><a href="/logs/papernotes.html" class="sidebar-link">paper reading notes</a></li><li><a href="/logs/pl.html" class="sidebar-link">PL</a></li><li><a href="/logs/R.html" class="sidebar-link">R</a></li><li><a href="/logs/RL.html" class="active sidebar-link">Reinforcement Learning</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/logs/RL.html#post" class="sidebar-link">post</a></li><li class="sidebar-sub-header"><a href="/logs/RL.html#tools" class="sidebar-link">tools</a></li><li class="sidebar-sub-header"><a href="/logs/RL.html#datasets" class="sidebar-link">datasets</a></li><li class="sidebar-sub-header"><a href="/logs/RL.html#workshops-confs" class="sidebar-link">workshops confs</a></li><li class="sidebar-sub-header"><a href="/logs/RL.html#exploration" class="sidebar-link">exploration</a></li><li class="sidebar-sub-header"><a href="/logs/RL.html#randomization-exploration-valuef" class="sidebar-link">Randomization(exploration, valueF)</a></li><li class="sidebar-sub-header"><a href="/logs/RL.html#initialization" class="sidebar-link">Initialization</a></li><li class="sidebar-sub-header"><a href="/logs/RL.html#simulation" class="sidebar-link">simulation</a></li><li class="sidebar-sub-header"><a href="/logs/RL.html#browser" class="sidebar-link">browser</a></li><li class="sidebar-sub-header"><a href="/logs/RL.html#testing-env" class="sidebar-link">testing env</a></li><li class="sidebar-sub-header"><a href="/logs/RL.html#model-based" class="sidebar-link">Model Based</a></li><li class="sidebar-sub-header"><a href="/logs/RL.html#residual-physics" class="sidebar-link">Residual physics</a></li><li class="sidebar-sub-header"><a href="/logs/RL.html#physics-control" class="sidebar-link">Physics control</a></li><li class="sidebar-sub-header"><a href="/logs/RL.html#state-abstraction" class="sidebar-link">State abstraction</a></li><li class="sidebar-sub-header"><a href="/logs/RL.html#distributed" class="sidebar-link">Distributed</a></li><li class="sidebar-sub-header"><a href="/logs/RL.html#source-of-supervision" class="sidebar-link">source of supervision</a></li><li class="sidebar-sub-header"><a href="/logs/RL.html#generalization" class="sidebar-link">Generalization</a></li><li class="sidebar-sub-header"><a href="/logs/RL.html#_3d-pose-mesh-kinematic-simulation" class="sidebar-link">3d pose, mesh, kinematic simulation</a></li><li class="sidebar-sub-header"><a href="/logs/RL.html#sample-efficiency" class="sidebar-link">sample  efficiency</a></li><li class="sidebar-sub-header"><a href="/logs/RL.html#others" class="sidebar-link">others</a></li></ul></li><li><a href="/logs/social.html" class="sidebar-link">Social</a></li><li><a href="/logs/vision.html" class="sidebar-link">Vision</a></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="reinforcement-learning"><a href="#reinforcement-learning" class="header-anchor">#</a> Reinforcement Learning</h1> <h2 id="post"><a href="#post" class="header-anchor">#</a> post</h2> <p>https://distill.pub/2019/paths-perspective-on-value-learning/</p> <h2 id="tools"><a href="#tools" class="header-anchor">#</a> tools</h2> <p><a href="https://github.com/facebookresearch/pyrobot" target="_blank" rel="noopener noreferrer">pyrobot<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p><a href="https://sites.google.com/view/replab/" target="_blank" rel="noopener noreferrer">Reproducible Low-Cost Arm Benchmark<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>, <a href="https://arxiv.org/pdf/1905.07447.pdf" target="_blank" rel="noopener noreferrer">report<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p><a href="https://github.com/mgbellemare/Arcade-Learning-Environment" target="_blank" rel="noopener noreferrer">ALE<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <h2 id="datasets"><a href="#datasets" class="header-anchor">#</a> datasets</h2> <h2 id="workshops-confs"><a href="#workshops-confs" class="header-anchor">#</a> workshops confs</h2> <p>http://spirl.info/2019/readings-compiled/</p> <p>RSS 2019</p> <h2 id="exploration"><a href="#exploration" class="header-anchor">#</a> exploration</h2> <p>Montezuma's revenge and pitfall</p> <blockquote><p><a href="https://arxiv.org/pdf/1901.10995.pdf" target="_blank" rel="noopener noreferrer">Go explore<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p></blockquote> <ul><li><ol><li>remember states that havepreviously been visited</li></ol></li> <li><ol start="2"><li>first return to a promising state (without exploration),then explore from it</li></ol></li> <li><ol start="3"><li>solve simulated environments through exploiting any available means (including by introducing determinism), then robustify (create a policy that can reliably perform the solution) via imitation learning.</li></ol></li></ul> <p><a href="https://www.alexirpan.com/2018/11/27/go-explore.html" target="_blank" rel="noopener noreferrer">critic<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <h2 id="randomization-exploration-valuef"><a href="#randomization-exploration-valuef" class="header-anchor">#</a> Randomization(exploration, valueF)</h2> <p>https://iosband.github.io/research.html</p> <h2 id="initialization"><a href="#initialization" class="header-anchor">#</a> Initialization</h2> <p><a href="https://arxiv.org/pdf/1703.02660.pdf" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> for the MuJoCo benchmarks, wider state initialization give you more gains than pretty much any change between RL algorithms and model architectures</p> <h2 id="simulation"><a href="#simulation" class="header-anchor">#</a> simulation</h2> <p>mujoco</p> <p>https://www.panda3d.org/</p> <p>http://bulletphysics.org/wordpress/</p> <p>https://developer.nvidia.com/physx-sdk</p> <p>http://www.ode.org/</p> <p>http://gazebosim.org/</p> <p>ODE and Gazebo have the contact support</p> <h2 id="browser"><a href="#browser" class="header-anchor">#</a> browser</h2> <p><a href="https://github.com/mrdoob/three.js/blob/master/examples/webgl_loader_stl.html" target="_blank" rel="noopener noreferrer">three.js stl loader<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <h2 id="testing-env"><a href="#testing-env" class="header-anchor">#</a> testing env</h2> <p>(openai gym)[]</p> <p><a href="https://arxiv.org/pdf/1801.00690.pdf" target="_blank" rel="noopener noreferrer">dm control<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p>Arcade Learning Environment(https://github.com/mgbellemare/Arcade-Learning-Environment)</p> <p>Roboschool(https://github.com/openai/roboschool)</p> <p><a href="https://github.com/deepmind/lab" target="_blank" rel="noopener noreferrer">DeepMind Lab<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p><a href="https://github.com/facebookresearch/ELF" target="_blank" rel="noopener noreferrer">ELF<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <h2 id="model-based"><a href="#model-based" class="header-anchor">#</a> Model Based</h2> <blockquote><p>PE-TS</p></blockquote> <p>aleatoric (inherent system stochasticity)</p> <p>epistemic (subjective uncertainty, due to limited data)</p> <p>Gaussian process</p> <p>is a stochastic process (a collection of random variables indexed by time or space), such that every finite collection of those random variables has a multivariate normal distribution, i.e. every finite linear combination of them is normally distributed.</p> <p>Ensembles of bootstrapped models</p> <p>CEM: samples actions from a distribution closer to previous action samples that yielded high reward</p> <p>Specifically, aleatoric state variance is the average variance of particles of same bootstrap,</p> <p>whilst epistemic state variance is the variance of the average of particles of same bootstrap indexes.</p> <h2 id="residual-physics"><a href="#residual-physics" class="header-anchor">#</a> Residual physics</h2> <p>Residual policy learning</p> <h2 id="physics-control"><a href="#physics-control" class="header-anchor">#</a> Physics control</h2> <p>fully-actuated in state (q,q˙) at time t if it is able to command any instantaneous acceleration in q
underactuated in state (q,q˙) at time t if it is not able to command an arbitrary instantaneous acceleration in  q</p> <h2 id="state-abstraction"><a href="#state-abstraction" class="header-anchor">#</a> State abstraction</h2> <blockquote><p>semi-mdp(Sutton 1999)</p></blockquote> <blockquote><p>(option-critic)[https://arxiv.org/pdf/1609.05140.pdf]</p></blockquote> <h2 id="distributed"><a href="#distributed" class="header-anchor">#</a> Distributed</h2> <h2 id="source-of-supervision"><a href="#source-of-supervision" class="header-anchor">#</a> source of supervision</h2> <blockquote><p>demonstration</p></blockquote> <p><a href="https://arxiv.org/pdf/1807.06919.pdf" target="_blank" rel="noopener noreferrer">back-play<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p>require env to be inversible, arbitraily resetting env to any states. <a href="https://storage.googleapis.com/pub-tools-public-publication-data/pdf/bb67802995f7af4c6ba948ede1acfc8756be7134.pdf" target="_blank" rel="noopener noreferrer">some env<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a> don't.</p> <p>(Learning to Select and GeneralizeStriking Movements in Robot Table Tennis)[https://www.aaai.org/ocs/index.php/FSS/FSS12/paper/viewFile/5602/5884]</p> <blockquote><p>language</p></blockquote> <p>(https://arxiv.org/pdf/1711.00482.pdf)[Learning with latent language]</p> <blockquote><p>human preference</p></blockquote> <h2 id="generalization"><a href="#generalization" class="header-anchor">#</a> Generalization</h2> <blockquote><p>Assessing Generalization in Deep Reinforcement Learning</p></blockquote> <p>variations in environment dynamics</p> <p>HalfCheetah under varying joint frictions.</p> <p>Each environment has three versions:
default; random; extreme</p> <p>EPOpt trains an agent to be robust to environment variations by maximizing a risk-sensitive reward
RL2 aims to learn a policy that can adapt to the environment at hand using the observed trajectory</p> <blockquote><p>A Dissection of Overfitting and Generalization inContinuous Reinforcement Learning</p></blockquote> <p>https://arxiv.org/pdf/1806.07937.pdf</p> <p>how to define and diagnose overfitting inMDPs, and how to reduce risks by injecting sufficient training diversity</p> <p>tasks that received observations from natural images and explore generalization in that setting as well</p> <p>as soon as there is enough training data diversity in thesimulated environment, deep RL generalizes well</p> <p>deepRL algorithms show more prominent overfitting when observing natural data.</p> <p>Results suggest that explicitly learning the dynamics model compounds existing bias in the datain the limited training seed regime</p> <p>a methodology for detecting overfitting</p> <p>eval-uation metrics for within-task and out-of-task generalization, consider two mechanisms for injecting noise intothe domain</p> <pre><code>- an expansion of the initial state distribution, which we implementby applying a multiplier to the initial state chosen.

- Second, we evaluate policy robustness by adding Gaussian noise n ∼ N(0,σ2) directly to theobservation space
</code></pre> <p>training random seeds</p> <p>generalization error: empirical error difference between test and training</p> <blockquote><p>https://arxiv.org/abs/1806.10729</p></blockquote> <p>procedural generation of video game levels during training to improve generalization to human-designed levels at test time</p> <blockquote><p>safety in grid world</p></blockquote> <p>https://deepmind.com/blog/specifying-ai-safety-problems/</p> <p>variations in environment dynamics</p> <blockquote><p>https://www.alexirpan.com/2018/02/14/rl-hard.html</p></blockquote> <blockquote><p>https://www.alexirpan.com/2017/06/27/hyperparam-spectral.html</p></blockquote> <blockquote><p>compare gym and dm environment</p></blockquote> <ul><li>reward function design</li> <li>does model fit to reward function design?</li> <li>change component behavior</li> <li>hidden instability</li></ul> <h1 id="underactuated-robotics"><a href="#underactuated-robotics" class="header-anchor">#</a> Underactuated Robotics</h1> <p>http://underactuated.csail.mit.edu/underactuated.html?chapter=intro</p> <blockquote><p>Quantile Regression Q learning</p></blockquote> <p>https://arxiv.org/abs/1710.10044</p> <p>https://mtomassoli.github.io/2017/12/08/distributional_rl/</p> <p>quantile Q(s,a) to atoms = \sum p_i x_i</p> <p>sample r, s' from replay buffer, then sample from r + \gamma Z(s', a_\star), quantile atoms to equidistant grids, compute cross-entropy loss</p> <p><strong>unify cross-entropy and KL divergence:</strong></p> <p>m is the prob of aligned atoms of $$ r + \gamma Z(x_{x+1}, a^{\star}) $$, and true prob $p(x_t, a_t; \theta)$ is aligned atoms of Z(x_t,a)</p> <p>derivatives of KL(m | p_{\theta}) wrt. \theta is derivative of entropy H(m, p_{\theta}), which is the gradient of cross entropy loss function $\sum m_i \log p_i(x_t, a_t; \theta)$</p> <blockquote><p>A Distributional Perspective on Reinforcement Learning</p></blockquote> <p>fixed quantile -&gt; variable length gaps</p> <p>slice to N equal mass, put atoms at median</p> <p>Huber loss for computing quantile gradient</p> <p><strong>Wasserstein metric</strong></p> <p>$$\mathcal{W}<em>{p}(X,Y)=\left(\int</em>{0}^{1}\left|F_{X}^{-1}(u)-F_{Y}^{-1}(u)\right|^{p}du\right)^{1/p}$$</p> <p>integrate discrepancy region, different between CDF</p> <p>W distance is reduced when medians are aligned</p> <p>why not simple regression:  the expectation of the quantiles are not the quantiles of the expectation</p> <blockquote><p>tune net</p></blockquote> <p>tune the simulation physics from physics in real world</p> <blockquote><p>human correction of pose keyframes</p></blockquote> <p>correction matrix to transform trajactories</p> <blockquote><p>diligent robot
hospital service robot</p></blockquote> <h2 id="_3d-pose-mesh-kinematic-simulation"><a href="#_3d-pose-mesh-kinematic-simulation" class="header-anchor">#</a> 3d pose, mesh, kinematic simulation</h2> <p><a href="https://github.com/xbpeng/DeepMimic" target="_blank" rel="noopener noreferrer">deepmimic<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <h2 id="sample-efficiency"><a href="#sample-efficiency" class="header-anchor">#</a> sample  efficiency</h2> <p>reward  shaping
behavioral cloning
reverse curriculum generation</p> <h2 id="others"><a href="#others" class="header-anchor">#</a> others</h2> <blockquote><p>sticky actions <a href="https://arxiv.org/pdf/1709.06009.pdf" target="_blank" rel="noopener noreferrer">section 5.2<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p></blockquote> <blockquote><p>Deep Reinforcement Learning that Matters</p></blockquote> <blockquote><p><a href="https://arxiv.org/abs/1803.07635" target="_blank" rel="noopener noreferrer">motion plan and NN<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p></blockquote></div> <footer class="page-edit"><div class="edit-link"><a href="https://github.com/josherich/blog/edit/master/logs/RL.md" target="_blank" rel="noopener noreferrer">在 GitHub 上编辑此页</a> <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></div> <!----></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/logs/R.html" class="prev">R</a></span> <span class="next"><a href="/logs/social.html">Social</a>
      →
    </span></p></div> </main></div><div class="global-ui"><SWUpdatePopup></SWUpdatePopup><!----></div></div>
    <script src="/logs/assets/js/app.09a71387.js" defer></script><script src="/logs/assets/js/2.5fba0fc3.js" defer></script><script src="/logs/assets/js/8.1099fc02.js" defer></script>
  </body>
</html>
