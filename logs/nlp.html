<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>NLP | Josherich logs</title>
    <meta name="description" content="Josherich logs">
    <link rel="icon" href="/logs/logo.png">
  <link rel="manifest" href="/logs/manifest.json">
  <meta name="theme-color" content="#fff">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
  <link rel="apple-touch-icon" href="/logs/apple-touch-icon.png">
  <link rel="mask-icon" href="/logs/safari-pinned-tab.svg" color="#ff8549">
    
    <link rel="preload" href="/logs/assets/css/0.styles.7191ec3a.css" as="style"><link rel="preload" href="/logs/assets/js/app.09a71387.js" as="script"><link rel="preload" href="/logs/assets/js/2.5fba0fc3.js" as="script"><link rel="preload" href="/logs/assets/js/21.f653a922.js" as="script"><link rel="prefetch" href="/logs/assets/js/10.d006e7a8.js"><link rel="prefetch" href="/logs/assets/js/11.fd749eab.js"><link rel="prefetch" href="/logs/assets/js/12.e197d713.js"><link rel="prefetch" href="/logs/assets/js/13.5faee3eb.js"><link rel="prefetch" href="/logs/assets/js/14.dd1edca1.js"><link rel="prefetch" href="/logs/assets/js/15.8ccfa7a9.js"><link rel="prefetch" href="/logs/assets/js/16.0254efc1.js"><link rel="prefetch" href="/logs/assets/js/17.e177a4da.js"><link rel="prefetch" href="/logs/assets/js/18.1cf5c84a.js"><link rel="prefetch" href="/logs/assets/js/19.0a4d2d26.js"><link rel="prefetch" href="/logs/assets/js/20.6ad277bf.js"><link rel="prefetch" href="/logs/assets/js/22.d66a1538.js"><link rel="prefetch" href="/logs/assets/js/23.c2b61054.js"><link rel="prefetch" href="/logs/assets/js/24.a688e03c.js"><link rel="prefetch" href="/logs/assets/js/25.ce0b2b01.js"><link rel="prefetch" href="/logs/assets/js/26.98393859.js"><link rel="prefetch" href="/logs/assets/js/27.9c56208f.js"><link rel="prefetch" href="/logs/assets/js/28.2b361e5f.js"><link rel="prefetch" href="/logs/assets/js/3.e79b47f3.js"><link rel="prefetch" href="/logs/assets/js/4.824b2f94.js"><link rel="prefetch" href="/logs/assets/js/5.cf7ef866.js"><link rel="prefetch" href="/logs/assets/js/6.d8e82984.js"><link rel="prefetch" href="/logs/assets/js/7.99d61cc4.js"><link rel="prefetch" href="/logs/assets/js/8.1099fc02.js"><link rel="prefetch" href="/logs/assets/js/9.64f7f7fe.js">
    <link rel="stylesheet" href="/logs/assets/css/0.styles.7191ec3a.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div class="theme-container"><header class="navbar"><div class="sidebar-button"><svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" role="img" viewBox="0 0 448 512" class="icon"><path fill="currentColor" d="M436 124H12c-6.627 0-12-5.373-12-12V80c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12zm0 160H12c-6.627 0-12-5.373-12-12v-32c0-6.627 5.373-12 12-12h424c6.627 0 12 5.373 12 12v32c0 6.627-5.373 12-12 12z"></path></svg></div> <a href="/logs/" class="home-link router-link-active"><!----> <span class="site-name">Josherich logs</span></a> <div class="links"><div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <nav class="nav-links can-hide"><div class="nav-item"><a href="/logs/" class="nav-link">Home</a></div> <a href="https://github.com/josherich/blog" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></nav></div></header> <div class="sidebar-mask"></div> <aside class="sidebar"><nav class="nav-links"><div class="nav-item"><a href="/logs/" class="nav-link">Home</a></div> <a href="https://github.com/josherich/blog" target="_blank" rel="noopener noreferrer" class="repo-link">
    GitHub
    <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></nav>  <ul class="sidebar-links"><li><section class="sidebar-group collapsable depth-0"><p class="sidebar-heading"><span>Home</span> <span class="arrow right"></span></p> <!----></section></li><li><section class="sidebar-group depth-0"><p class="sidebar-heading open"><span>Logs</span> <!----></p> <ul class="sidebar-links sidebar-group-items"><li><a href="/logs/logs.html" class="sidebar-link">Logs</a></li><li><a href="/logs/cloud.html" class="sidebar-link">cloud</a></li><li><a href="/logs/cpp.html" class="sidebar-link">CPP</a></li><li><a href="/logs/cs.html" class="sidebar-link">CS</a></li><li><a href="/logs/database.html" class="sidebar-link">Database</a></li><li><a href="/logs/draw.html" class="sidebar-link">Draw</a></li><li><a href="/logs/frontend.html" class="sidebar-link">Front end</a></li><li><a href="/logs/gaming.html" class="sidebar-link">Books</a></li><li><a href="/logs/josherich.html" class="sidebar-link">Josherich</a></li><li><a href="/logs/languages.html" class="sidebar-link">Language</a></li><li><a href="/logs/math.html" class="sidebar-link">Math</a></li><li><a href="/logs/ml.html" class="sidebar-link">Machine Learning</a></li><li><a href="/logs/nlp.html" class="active sidebar-link">NLP</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/logs/nlp.html#recent-paper-list" class="sidebar-link">Recent paper list</a></li><li class="sidebar-sub-header"><a href="/logs/nlp.html#recent-post-list" class="sidebar-link">recent post list</a></li><li class="sidebar-sub-header"><a href="/logs/nlp.html#corpus" class="sidebar-link">corpus</a></li><li class="sidebar-sub-header"><a href="/logs/nlp.html#datasets" class="sidebar-link">Datasets</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/logs/nlp.html#multilingual" class="sidebar-link">Multilingual</a></li><li class="sidebar-sub-header"><a href="/logs/nlp.html#chinese" class="sidebar-link">Chinese</a></li><li class="sidebar-sub-header"><a href="/logs/nlp.html#nlu" class="sidebar-link">NLU</a></li><li class="sidebar-sub-header"><a href="/logs/nlp.html#text-classification" class="sidebar-link">text classification</a></li><li class="sidebar-sub-header"><a href="/logs/nlp.html#reading-comprehension" class="sidebar-link">Reading comprehension</a></li></ul></li><li class="sidebar-sub-header"><a href="/logs/nlp.html#tools" class="sidebar-link">Tools</a></li><li class="sidebar-sub-header"><a href="/logs/nlp.html#tasks" class="sidebar-link">Tasks</a></li><li class="sidebar-sub-header"><a href="/logs/nlp.html#tree-embedding" class="sidebar-link">Tree embedding</a></li><li class="sidebar-sub-header"><a href="/logs/nlp.html#byte-pair-encoding" class="sidebar-link">Byte Pair Encoding</a></li><li class="sidebar-sub-header"><a href="/logs/nlp.html#subword-neural-machine-translation" class="sidebar-link">Subword Neural Machine Translation</a></li><li class="sidebar-sub-header"><a href="/logs/nlp.html#weight-sharing" class="sidebar-link">weight sharing</a></li><li class="sidebar-sub-header"><a href="/logs/nlp.html#gibbs-sampling-for-posterior-distribution" class="sidebar-link">Gibbs sampling for posterior distribution</a></li><li class="sidebar-sub-header"><a href="/logs/nlp.html#computing-attention-score" class="sidebar-link">computing attention score</a></li><li class="sidebar-sub-header"><a href="/logs/nlp.html#char-based-and-subword-based-models" class="sidebar-link">char-based and subword-based models</a></li><li class="sidebar-sub-header"><a href="/logs/nlp.html#char-aware-models" class="sidebar-link">char-aware models</a></li><li class="sidebar-sub-header"><a href="/logs/nlp.html#open-vocabulary-hybrid-models" class="sidebar-link">open-vocabulary hybrid models</a></li><li class="sidebar-sub-header"><a href="/logs/nlp.html#mixture-model-generation" class="sidebar-link">mixture model generation</a></li><li class="sidebar-sub-header"><a href="/logs/nlp.html#level-of-nlp-research" class="sidebar-link">level of NLP research</a></li><li class="sidebar-sub-header"><a href="/logs/nlp.html#vision-and-language-navigation" class="sidebar-link">Vision-and-Language Navigation</a></li><li class="sidebar-sub-header"><a href="/logs/nlp.html#linguistics" class="sidebar-link">Linguistics</a></li><li class="sidebar-sub-header"><a href="/logs/nlp.html#transition-based-dependency-parsing" class="sidebar-link">Transition based dependency parsing</a></li><li class="sidebar-sub-header"><a href="/logs/nlp.html#training-oracle" class="sidebar-link">Training oracle</a></li><li class="sidebar-sub-header"><a href="/logs/nlp.html#universal-dependency-set" class="sidebar-link">Universal Dependency Set</a><ul class="sidebar-sub-headers"><li class="sidebar-sub-header"><a href="/logs/nlp.html#nlp-and-text-as-data-speaker-series" class="sidebar-link">NLP and Text as Data Speaker Series</a></li><li class="sidebar-sub-header"><a href="/logs/nlp.html#future-philologies-digital-directions-in-ancient-world-text" class="sidebar-link">Future Philologies - Digital Directions in Ancient World Text</a></li></ul></li><li class="sidebar-sub-header"><a href="/logs/nlp.html#services-corps" class="sidebar-link">services, corps</a></li></ul></li><li><a href="/logs/numpy.html" class="sidebar-link">Numpy</a></li><li><a href="/logs/ops.html" class="sidebar-link">Ops</a></li><li><a href="/logs/os.html" class="sidebar-link">OS</a></li><li><a href="/logs/papernotes.html" class="sidebar-link">paper reading notes</a></li><li><a href="/logs/pl.html" class="sidebar-link">PL</a></li><li><a href="/logs/R.html" class="sidebar-link">R</a></li><li><a href="/logs/RL.html" class="sidebar-link">Reinforcement Learning</a></li><li><a href="/logs/social.html" class="sidebar-link">Social</a></li><li><a href="/logs/vision.html" class="sidebar-link">Vision</a></li></ul></section></li></ul> </aside> <main class="page"> <div class="theme-default-content content__default"><h1 id="nlp"><a href="#nlp" class="header-anchor">#</a> NLP</h1> <h2 id="recent-paper-list"><a href="#recent-paper-list" class="header-anchor">#</a> Recent paper list</h2> <blockquote><p><a href="https://pair-code.github.io/interpretability/bert-tree/" target="_blank" rel="noopener noreferrer">Tree embedding<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p></blockquote> <blockquote><p><a href="https://github.com/ymcui/Chinese-BERT-wwm" target="_blank" rel="noopener noreferrer">BERT chinese whole word masking<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p></blockquote> <blockquote><p><a href="https://arxiv.org/pdf/1906.02715.pdf" target="_blank" rel="noopener noreferrer">visualize BERT<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p></blockquote> <blockquote><p><a href="https://arxiv.org/pdf/1904.05298.pdf" target="_blank" rel="noopener noreferrer">model lang model using quantum physics<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p></blockquote> <p>naacl 2019
https://github.com/wabyking/qnn
https://mp.weixin.qq.com/s/NbLnGQD4TjlbMGOXbfa8pg</p> <blockquote><p><a href="https://trec.nist.gov/pubs/trec27/papers/NYU-DL-CAR.pdf" target="_blank" rel="noopener noreferrer">TREC-CAR task<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p></blockquote> <p>TREC-CAR task:</p> <p>query is wikipedia title concatenated with section titles, answer is the wikipedia page text</p> <p>query_0 -&gt; multi reformulator -&gt; search results -&gt; aggregator</p> <p>use RL to train reformulator agents (state is documents, reward r is )</p> <p>aggragator as meta-agent</p> <ul><li>accum rank score s_A, relavence(CNN/LSTM), top-k answer wrt s = s_R s_A</li></ul> <blockquote><p><a href="https://arxiv.org/pdf/1601.03764.pdf" target="_blank" rel="noopener noreferrer">polysemy in word embedding<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p></blockquote> <p>multiple word senses reside in linear superposition within the wordembedding and simple sparse coding can re-cover vectors that approximately capture the senses.</p> <p>polysemy vector is linear combination of its monosemous vectors</p> <ul><li><p>linearity Assertion linear structure appears out of a highly nonlinearembedding</p></li> <li><p>Word Sense Induction via sparse coding</p></li></ul> <blockquote><p>random walk on discourses</p></blockquote> <p>random walk across micro-topics(discourse)</p> <p>there exists a linear relationship between the vector of aword and the vectors of the words in its contexts</p> <blockquote><p><a href="https://www.aclweb.org/anthology/W17-1902" target="_blank" rel="noopener noreferrer">Automated WordNet Construction Using Word Embeddings<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p></blockquote> <blockquote><p><a href="http://homepages.inf.ed.ac.uk/mlap/Papers/jair09.pdf" target="_blank" rel="noopener noreferrer">Sentence Compression as Tree Transduction<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p></blockquote> <p>tree-to-tree transduction method for sentence compression</p> <blockquote><p><a href="http://socsci.uci.edu/~rfutrell/papers/futrell2017memory.pdf" target="_blank" rel="noopener noreferrer">memory and locality in NLP<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p></blockquote> <blockquote><p><a href="http://socsci.uci.edu/~rfutrell/papers/futrell2019rnns.pdf" target="_blank" rel="noopener noreferrer">lstm preserve word order preference<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p></blockquote> <blockquote><p>[code2vec](code2vec: Learning Distributed Representations of Code)</p></blockquote> <blockquote><p><a href="https://github.com/pmichel31415/are-16-heads-really-better-than-1" target="_blank" rel="noopener noreferrer">transformer 1 head<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p></blockquote> <blockquote><p><a href="https://github.com/HazyResearch/metal/blob/master/tutorials/MMTL_Basics.ipynb" target="_blank" rel="noopener noreferrer">Snorkel MeTaL basic<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p></blockquote> <blockquote><p><a href="https://github.com/hazyresearch/fonduer-tutorials" target="_blank" rel="noopener noreferrer">knowledge base construction fonduer<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p></blockquote> <blockquote><p><a href="https://github.com/namisan/mt-dnn" target="_blank" rel="noopener noreferrer">multi task NLU<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p></blockquote> <h2 id="recent-post-list"><a href="#recent-post-list" class="header-anchor">#</a> recent post list</h2> <p>entity link: https://spaces.ac.cn/archives/6919</p> <h2 id="corpus"><a href="#corpus" class="header-anchor">#</a> corpus</h2> <ul><li><p><a href="https://github.com/google-research-datasets/natural-questions" target="_blank" rel="noopener noreferrer">natural questions<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p></li> <li><p><a href="https://pmb.let.rug.nl/explorer/explore.php" target="_blank" rel="noopener noreferrer">parallel meaning bank<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p></li> <li><p><a href="">BooksCorpus</a></p></li> <li><p><a href="">Eng wikipedia</a></p></li> <li><p><a href="">Giga5 16GB</a></p></li> <li><p><a href="">ClueWeb 2012B</a></p></li> <li><p><a href="">CommonCrawl</a></p></li> <li><p><a href="https://github.com/OYE93/Chinese-NLP-Corpus" target="_blank" rel="noopener noreferrer">cn corpus<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p></li> <li><p><a href="https://github.com/nert-nlp/streusle" target="_blank" rel="noopener noreferrer">streusle, lexical semantic annotation<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p></li></ul> <h2 id="datasets"><a href="#datasets" class="header-anchor">#</a> Datasets</h2> <h3 id="multilingual"><a href="#multilingual" class="header-anchor">#</a> Multilingual</h3> <p>https://github.com/facebookresearch/MLDoc</p> <h3 id="chinese"><a href="#chinese" class="header-anchor">#</a> Chinese</h3> <p><a href="https://github.com/ymcui/cmrc2018" target="_blank" rel="noopener noreferrer">CMRC<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p><a href="https://github.com/DRCKnowledgeTeam/DRCD" target="_blank" rel="noopener noreferrer">DRCD<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>
https://arxiv.org/pdf/1806.00920.pdf</p> <p><a href="http://sighan.cs.uchicago.edu/bakeoff2006/" target="_blank" rel="noopener noreferrer">people daily NER/MSRA NER<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p><a href="http://thuctc.thunlp.org/#%E4%B8%AD%E6%96%87%E6%96%87%E6%9C%AC%E5%88%86%E7%B1%BB%E6%95%B0%E6%8D%AE%E9%9B%86THUCNews" target="_blank" rel="noopener noreferrer">THUCNews<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <h3 id="nlu"><a href="#nlu" class="header-anchor">#</a> NLU</h3> <p><a href="http://fever.ai/resources.html" target="_blank" rel="noopener noreferrer">fever Fact Extraction and VERification<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p><a href="https://yale-lily.github.io/spider" target="_blank" rel="noopener noreferrer">spider<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p><a href="https://arxiv.org/pdf/1606.06031.pdf" target="_blank" rel="noopener noreferrer">LAMBADA dataset<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>
long dependency, predict last word</p> <p>XNLI</p> <p>SNLI, MNLI</p> <p>babi</p> <p><a href="https://voice.mozilla.org/en" target="_blank" rel="noopener noreferrer">mozilla voice<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p><a href="https://github.com/imhuster/funNLP" target="_blank" rel="noopener noreferrer">cn words<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p><a href="https://github.com/thunlp/Chinese_Rumor_Dataset" target="_blank" rel="noopener noreferrer">cn rumors weibo<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p><a href="">wikitext-2</a>
'train': &quot;https://s3.amazonaws.com/datasets.huggingface.co/wikitext-2/train.txt&quot;
'valid': &quot;https://s3.amazonaws.com/datasets.huggingface.co/wikitext-2/valid.txt&quot;</p> <p><a href="">wikitext-103</a>
'train': &quot;https://s3.amazonaws.com/datasets.huggingface.co/wikitext-103/wiki.train.tokens&quot;
'valid': &quot;https://s3.amazonaws.com/datasets.huggingface.co/wikitext-103/wiki.valid.tokens&quot;</p> <p><a href="">simplebooks-2-raw</a>
: {'train': &quot;https://s3.amazonaws.com/datasets.huggingface.co/simplebooks-2-raw/train.txt&quot;,
'valid': &quot;https://s3.amazonaws.com/datasets.huggingface.co/simplebooks-2-raw/valid.txt&quot;},
<a href="">simplebooks-92-raw</a>
: {'train': &quot;https://s3.amazonaws.com/datasets.huggingface.co/simplebooks-92-raw/train.txt&quot;,
'valid': &quot;https://s3.amazonaws.com/datasets.huggingface.co/simplebooks-92-raw/valid.txt&quot;},
<a href="">imdb</a>
: {'train': &quot;https://s3.amazonaws.com/datasets.huggingface.co/aclImdb/train.txt&quot;,
'test': &quot;https://s3.amazonaws.com/datasets.huggingface.co/aclImdb/test.txt&quot;},
<a href="">trec</a>
{'train': &quot;https://s3.amazonaws.com/datasets.huggingface.co/trec/train.txt&quot;,
'test': &quot;https://s3.amazonaws.com/datasets.huggingface.co/trec/test.txt&quot;}</p> <ul><li><p><a href="http://lil.nlp.cornell.edu/nlvr/index.html" target="_blank" rel="noopener noreferrer">nlvr<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p></li> <li><p><a href="https://conala-corpus.github.io/" target="_blank" rel="noopener noreferrer">conala<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>, Code/Natural Language Challenge</p></li> <li><p><a href="https://bringmeaspoon.org/" target="_blank" rel="noopener noreferrer">room to room<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p></li></ul> <h3 id="text-classification"><a href="#text-classification" class="header-anchor">#</a> text classification</h3> <p>IMDB</p> <p>Yelp-2, Yelp-5</p> <p>DBpedia</p> <p>AG</p> <p>Amazon-2, Amazon-5</p> <h3 id="reading-comprehension"><a href="#reading-comprehension" class="header-anchor">#</a> Reading comprehension</h3> <ul><li><p>common QA</p></li> <li><p><a href="http://www.qizhexie.com/data/RACE_leaderboard" target="_blank" rel="noopener noreferrer">RACE reading compreh<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a>
100k in size</p> <blockquote><p>300 average length</p></blockquote></li> <li><p><a href="">MCTest</a>
design for 7 years old
500 stores and 2k questions</p></li></ul> <blockquote><p>cloze-style</p></blockquote> <ul><li><p><a href="">CNN/Daily mail</a></p></li> <li><p><a href="">CBT children book test, book test</a></p></li> <li><p><a href="">who did what</a></p></li></ul> <blockquote><p>span based</p></blockquote> <ul><li><p>SQUAD
unanswerable questions</p></li> <li><p>NEWSQA</p></li> <li><p>MSMARCO</p></li></ul> <blockquote><p>exam based</p></blockquote> <ul><li><p>[AI2 Elementary SchoolScience Questions]
1080 questions</p></li> <li><p>[NTCIR  QA  Lab]
university entrance</p></li> <li><p>[CLEF QA Track]</p></li></ul> <p>WSCR</p> <h2 id="tools"><a href="#tools" class="header-anchor">#</a> Tools</h2> <p><a href="https://github.com/fnl/syntok" target="_blank" rel="noopener noreferrer">syntok sent segment<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p><a href="https://github.com/kaushaltrivedi/bert-toxic-comments-multilabel/blob/master/toxic-bert-multilabel-classification.ipynb" target="_blank" rel="noopener noreferrer">BERT multi label<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p><a href="https://decanlp.com/" target="_blank" rel="noopener noreferrer">decanlp<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p><a href="https://ai.tencent.com/ailab/nlp/embedding.html" target="_blank" rel="noopener noreferrer">tecent ai word embedding<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p><a href="https://github.com/CLD2Owners/cld2" target="_blank" rel="noopener noreferrer">lang detector<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p><a href="https://github.com/pytorch/fairseq" target="_blank" rel="noopener noreferrer">fairseq<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p><a href="https://github.com/facebookresearch/nevergrad/blob/master/README.md" target="_blank" rel="noopener noreferrer">nevergrad<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p><a href="https://github.com/facebookresearch/XLM" target="_blank" rel="noopener noreferrer">XLM<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p><a href="https://github.com/imhuster/funNLP" target="_blank" rel="noopener noreferrer">cn words<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p><a href="https://github.com/google/sentencepiece" target="_blank" rel="noopener noreferrer">sentence piece tokenizer<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <h2 id="tasks"><a href="#tasks" class="header-anchor">#</a> Tasks</h2> <blockquote><p>Pairwise Relations</p></blockquote> <ul><li>arc classification</li> <li>arc prediction(binary)</li></ul> <blockquote><p>Preposition supersense disambiguation</p></blockquote> <p>STREUSLE 4.0 corpus</p> <blockquote><p>semantic tagging</p></blockquote> <blockquote><p>event factuality</p></blockquote> <p><a href="http://decomp.io/data/" target="_blank" rel="noopener noreferrer">Universal Decompositional Semantics It Happened v2<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <blockquote><p>Grammatical error detection</p></blockquote> <p>https://ilexir.co.uk/datasets/index.html</p> <blockquote><p>conjunct identification</p></blockquote> <p>https://github.com/Jess1ca/CoordinationExtPTB</p> <blockquote><p>Document-level Generation and Translation</p></blockquote> <p><a href="https://sites.google.com/view/wngt19/dgt-task" target="_blank" rel="noopener noreferrer">2019 Shared Task<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <blockquote><p>Dependency parsing</p></blockquote> <ul><li><p>head and dependent</p></li> <li><p>the structure must be connected, have a designated root node, and be acyclic or planar.</p></li> <li><p>each word has a single head.</p></li> <li><p>there is a single root node from which one can follow a unique directed path to each of the words in the sentence.</p></li> <li><p>projective, if there is a path from the head to every word that lies between the head and the dependent in the sentence.</p></li> <li><p>a tree is projective, if it can be drawn with no crossing edges.</p></li> <li><p>non-projective, seen in flexible langauages.</p></li></ul> <blockquote><p>Translation, text, audio</p></blockquote> <blockquote><p>Graph based dependency parsing</p></blockquote> <ul><li><p>score the tree with edge weights</p></li> <li><p>using maximum spanning tree, but might have cycles</p></li> <li><p>to eliminate cycles, Chu, Liu, Edmonds(1967):</p></li></ul> <ol><li><p>for each vertex, incoming edge with max weight is chosen</p></li> <li><p>subtract each incoming edges with max incoming weight.</p></li> <li><p>select a cycle and collapse it into a single new node.</p></li></ol> <blockquote><p>higher order dependency parsing</p></blockquote> <p>Zhang and McDonald 2012</p> <h1 id="technique"><a href="#technique" class="header-anchor">#</a> Technique</h1> <h2 id="tree-embedding"><a href="#tree-embedding" class="header-anchor">#</a> Tree embedding</h2> <blockquote><p>https://pair-code.github.io/interpretability/bert-tree/</p></blockquote> <pre><code>𝑛  vectors completely at random from a unit Gaussian distribution in ℝ𝑚. If 𝑚≫𝑛, with high probability the result would be an approximate Pythagorean embedding.

The reason is that in high dimensions, (1) vectors drawn from a unit Gaussian distribution have length very close to 1 with high probability; and (2) when 𝑚≫𝑛, a set of 𝑛 unit Gaussian vectors will likely be close to mutually orthogonal.

Initialize with a completely random tree embedding, and in addition pick a special random vector for each vertex; then at each step, move each child node so that it is closer to its parent's location plus the child's special vector

&gt; [A Structural Probe for Finding Syntax in Word Representations](https://nlp.stanford.edu/pubs/hewitt2019structural.pdf)
  https://github.com/john-hewitt/structural-probes
</code></pre> <h2 id="byte-pair-encoding"><a href="#byte-pair-encoding" class="header-anchor">#</a> Byte Pair Encoding</h2> <h2 id="subword-neural-machine-translation"><a href="#subword-neural-machine-translation" class="header-anchor">#</a> Subword Neural Machine Translation</h2> <p>https://github.com/rsennrich/subword-nmt</p> <h2 id="weight-sharing"><a href="#weight-sharing" class="header-anchor">#</a> weight sharing</h2> <p>https://github.com/deepmind/sonnet/blob/master/docs/README.md</p> <h2 id="gibbs-sampling-for-posterior-distribution"><a href="#gibbs-sampling-for-posterior-distribution" class="header-anchor">#</a> Gibbs sampling for posterior distribution</h2> <p>The idea in Gibbs sampling is to generate posterior samplesby  sweeping  through  each  variable  (or  block  of  variables)  to  sample  from  its  conditionaldistribution with the remaining variables fixed to their current values.</p> <h1 id="methods-algorithms"><a href="#methods-algorithms" class="header-anchor">#</a> methods, algorithms</h1> <h2 id="computing-attention-score"><a href="#computing-attention-score" class="header-anchor">#</a> computing attention score</h2> <ul><li><p>dot product</p></li> <li><p>bilinear</p></li> <li><p>multi-layer perceptron</p></li></ul> <h2 id="char-based-and-subword-based-models"><a href="#char-based-and-subword-based-models" class="header-anchor">#</a> char-based and subword-based models</h2> <p>namesake (Markov 1906)</p> <p>Sutskever et el. 2011</p> <p>Mikolov el al. 2012, Sennrich el al. 2015</p> <h2 id="char-aware-models"><a href="#char-aware-models" class="header-anchor">#</a> char-aware models</h2> <p>char and word level (Kang el al. 2011) (Ling el al. 2015) (Kim el al. 2016)</p> <p>unsupervised morphology with log-bilinear model (Botha and Blunsom 2014)(Jozefowicz el al. 2016)</p> <h2 id="open-vocabulary-hybrid-models"><a href="#open-vocabulary-hybrid-models" class="header-anchor">#</a> open-vocabulary hybrid models</h2> <p>Brown el al. 1992</p> <p>Chung el al. 2016</p> <p>Luong and Manning 2016</p> <h2 id="mixture-model-generation"><a href="#mixture-model-generation" class="header-anchor">#</a> mixture model generation</h2> <p>combine count based and neural lm (Neubig Dyer 2016)</p> <p>char based and word based to translate text and code (Ling el al 2016)</p> <p>copy when UNK (Merity et al. 2016)</p> <h1 id="misc-theories"><a href="#misc-theories" class="header-anchor">#</a> Misc theories</h1> <blockquote><p><a href="http://interpretable.ml/" target="_blank" rel="noopener noreferrer">interpretable ML NIPS 2017<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p></blockquote> <h2 id="level-of-nlp-research"><a href="#level-of-nlp-research" class="header-anchor">#</a> level of NLP research</h2> <ul><li><p>Phonetics and phonology</p></li> <li><p>Morphology</p></li> <li><p>Syntax</p></li> <li><p>Lexical semantics</p></li> <li><p>Compositional semantics</p></li> <li><p>Pragmatics</p></li> <li><p>Discourse</p></li></ul> <h2 id="vision-and-language-navigation"><a href="#vision-and-language-navigation" class="header-anchor">#</a> Vision-and-Language Navigation</h2> <p>andreas</p> <p><a href="https://arxiv.org/pdf/1905.13358.pdf" target="_blank" rel="noopener noreferrer">a discriminator that evalu-ates how well an instruction explains a givenpath in VLN task using multi-modal alignment<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p>dataset: <a href="http://bringmeaspoon.org/" target="_blank" rel="noopener noreferrer">room to room<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <h1 id="chomsky-hierarchy-of-languages-and-grammars"><a href="#chomsky-hierarchy-of-languages-and-grammars" class="header-anchor">#</a> Chomsky hierarchy of languages and grammars</h1> <blockquote><p>parsing technique</p></blockquote> <p>type 1</p> <p>type 2</p> <p>type 3</p> <p>type 4</p> <h2 id="linguistics"><a href="#linguistics" class="header-anchor">#</a> Linguistics</h2> <blockquote><p>heavy NP Shift</p></blockquote> <p>verb + NP + PP(temporal adjunct), if NP is heavy enough, PP will be shifted after verb</p> <blockquote><p>hrasal verbs and particle shift</p></blockquote> <p>give the habit up / give up the habit</p> <blockquote><p>dative alternation</p></blockquote> <p>give the woman the object / give the object to the woman</p> <p>double object / propositional object</p> <blockquote><p>Genitive altenation</p></blockquote> <p>the woman's house / the house of the woman</p> <h2 id="transition-based-dependency-parsing"><a href="#transition-based-dependency-parsing" class="header-anchor">#</a> Transition based dependency parsing</h2> <ul><li><p>configuration</p> <ul><li>stack,</li> <li>input buffer,</li> <li>relations</li></ul></li> <li><p>arc standard</p> <ul><li>leftArc</li> <li>rightArc</li> <li>shift</li></ul></li> <li><p>high accuracy on shorter denpendency relations but accurary declines significantly as the distance between head and dependent increases.</p></li></ul> <h2 id="training-oracle"><a href="#training-oracle" class="header-anchor">#</a> Training oracle</h2> <ol><li>generate training data, by simulation a given reference parse</li></ol> <p>one change to the rule: choose rightarc if it produces a correct relation given reference parsing, and, all dependents of the top word in stack have been assigned.</p> <ol start="2"><li>features</li></ol> <p>combine simples features, use feature template: <strong>location.property</strong></p> <ul><li>s: stack</li> <li>b: buffer</li> <li>w: word forms</li> <li>r: set of relations</li> <li>l: lemmas</li> <li>t: part-of-speech</li></ul> <ol start="3"><li>learning</li></ol> <h2 id="universal-dependency-set"><a href="#universal-dependency-set" class="header-anchor">#</a> Universal Dependency Set</h2> <ul><li><p>clausal relation, that describe syntatic roles with respect to predicate(often a verb)</p></li> <li><p>modifier relations, that categorize the ways that words can modify theirs heads.</p></li></ul> <table><thead><tr><th>Clausal Argument Relations</th> <th>Description</th></tr></thead> <tbody><tr><td>NSUBJ</td> <td>Nominal subject</td></tr> <tr><td>DOBJ</td> <td>Direct Object</td></tr> <tr><td>IOBJ</td> <td>Indirect Object</td></tr> <tr><td>CCOMP</td> <td>clausal complement</td></tr> <tr><td>XCOMP</td> <td>open clausal complement</td></tr></tbody></table> <table><thead><tr><th>Nominal Modifier Relations</th> <th>Description</th></tr></thead> <tbody><tr><td>NMOD</td> <td>Nominal Modifier</td></tr> <tr><td>AMOD</td> <td>Adjective modifier</td></tr> <tr><td>NUMMOD</td> <td>Numeric modifier</td></tr> <tr><td>APPOS</td> <td>appositional modifier</td></tr> <tr><td>DET</td> <td>determiner</td></tr> <tr><td>CASE</td> <td>Prepositions, postpositions and other case markers</td></tr></tbody></table> <table><thead><tr><th>others</th> <th>Description</th></tr></thead> <tbody><tr><td>CONJ</td> <td>Conjunct</td></tr> <tr><td>CC</td> <td>Coordinationg conjunction</td></tr></tbody></table> <h1 id="nlp-talks"><a href="#nlp-talks" class="header-anchor">#</a> NLP Talks</h1> <h3 id="nlp-and-text-as-data-speaker-series"><a href="#nlp-and-text-as-data-speaker-series" class="header-anchor">#</a> NLP and Text as Data Speaker Series</h3> <p>https://cds.nyu.edu/text-data-speaker-series/</p> <h4 id="towards-understanding-deep-learning-for-natural-language-processing-omer-levy"><a href="#towards-understanding-deep-learning-for-natural-language-processing-omer-levy" class="header-anchor">#</a> Towards Understanding Deep Learning for Natural Language Processing - Omer levy</h4> <p>https://levyomer.wordpress.com/publications/</p> <h4 id="what-are-neural-sequence-models-doing-kevin-knight"><a href="#what-are-neural-sequence-models-doing-kevin-knight" class="header-anchor">#</a> What are Neural Sequence Models Doing - kevin knight</h4> <p>https://kevincrawfordknight.github.io/</p> <h4 id="structured-embedding-models-for-language-variation-maja-rudolph"><a href="#structured-embedding-models-for-language-variation-maja-rudolph" class="header-anchor">#</a> Structured Embedding Models for Language Variation - Maja Rudolph</h4> <p>https://scholar.google.com/citations?user=QW_JZnsAAAAJ&amp;hl=en</p> <p>https://arxiv.org/pdf/1608.00778.pdf</p> <h4 id="unsupervised-models-of-conversational-dynamics-justine-zhang"><a href="#unsupervised-models-of-conversational-dynamics-justine-zhang" class="header-anchor">#</a> Unsupervised Models of Conversational Dynamics - Justine Zhang</h4> <p>http://tisjune.github.io/research/</p> <h4 id="end-to-end-learning-for-broad-coverage-semantics-luke-zettlemoyer"><a href="#end-to-end-learning-for-broad-coverage-semantics-luke-zettlemoyer" class="header-anchor">#</a> End-to-end Learning for Broad Coverage Semantics - Luke Zettlemoyer</h4> <p>https://www.cs.washington.edu/people/faculty/lsz/publications-by-year</p> <h4 id="what-can-neural-networks-teach-us-about-language"><a href="#what-can-neural-networks-teach-us-about-language" class="header-anchor">#</a> What Can Neural Networks Teach us about Language?</h4> <p>http://www.phontron.com/</p> <h4 id="unsupervised-methods-for-extracting-political-positions-from-text-ben-lauderdale"><a href="#unsupervised-methods-for-extracting-political-positions-from-text-ben-lauderdale" class="header-anchor">#</a> Unsupervised Methods for Extracting Political Positions from Text - Ben Lauderdale</h4> <p>http://benjaminlauderdale.net/</p> <h3 id="future-philologies-digital-directions-in-ancient-world-text"><a href="#future-philologies-digital-directions-in-ancient-world-text" class="header-anchor">#</a> Future Philologies - Digital Directions in Ancient World Text</h3> <p>Institute for the Study of the Ancient World
the ISAW Library
NYU Center for Humanities
NYU Division of Libraries
NYU Center for Ancient Studies and NYU Department of Classics</p> <p>https://diyclassics.github.io/future-philologies/</p> <h4 id="kyle-p-johnson-accenture-on-historical-text-and-natural-language-processing-the-next-700-classical-languages"><a href="#kyle-p-johnson-accenture-on-historical-text-and-natural-language-processing-the-next-700-classical-languages" class="header-anchor">#</a> Kyle P. Johnson (Accenture), on historical text and natural language processing, &quot;The Next 700 Classical Languages&quot;</h4> <p>http://kyle-p-johnson.com/</p> <h4 id="historical-text-and-information-retrieval-authorship-and-translation-bilingual-modeling-of-the-patrologia-graeca-david-mimno-and-laure-thompson"><a href="#historical-text-and-information-retrieval-authorship-and-translation-bilingual-modeling-of-the-patrologia-graeca-david-mimno-and-laure-thompson" class="header-anchor">#</a> Historical text and information retrieval, &quot;Authorship and Translation: Bilingual Modeling of the Patrologia Graeca&quot; - David Mimno and Laure Thompson</h4> <p>https://mimno.infosci.cornell.edu/</p> <h4 id="historical-text-and-machine-learning-viral-texts-and-networked-authors-computational-models-of-information-propagation-david-smith"><a href="#historical-text-and-machine-learning-viral-texts-and-networked-authors-computational-models-of-information-propagation-david-smith" class="header-anchor">#</a> Historical text and machine learning, &quot;Viral Texts and Networked Authors: Computational Models of Information Propagation&quot; - David Smith</h4> <p>http://www.ccs.neu.edu/home/dasmith/</p> <h1 id="cola"><a href="#cola" class="header-anchor">#</a> CoLA</h1> <p><a href="https://arxiv.org/pdf/1805.12471.pdf" target="_blank" rel="noopener noreferrer">Neural Network Acceptability Judgments<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <p>includes generative grammars of the type described by Chomsky (1957)</p> <p>isolate a violation, so tend to be unacceptable for a single identifiable reason.</p> <p>the artificial learner must not be ex-posed to any knowledge of language that could not plausibly be part of the input to a human learner</p> <p>100k most frequent words in the British National Corpus</p> <p>in-domain: training set (8551 examples), a development set (527), and a test set (530), 17 sources</p> <p>out-domain development set (516) and a test set (533), 6 sources</p> <p>human 86.1%</p> <p>aggregate rating, yielding an average agreement of 93%</p> <p>The encoders are trained on 100- 200 million tokens, which is within a factor of ten of the number of tokens human learners are ex- posed to during language acquisition</p> <blockquote><p><a href="https://arxiv.org/pdf/1611.01368.pdf" target="_blank" rel="noopener noreferrer">Assessing the Ability of LSTMs to Learn Syntax-Sensitive Dependencies<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p></blockquote> <p>subject-verb number agreement</p> <p>highly sensitive to recent but irrelevant nouns</p> <p>agreement attractors</p> <p>one-hot encoding input lstm 50 units: 0.83% errors</p> <p>nouns-only baseline: 4.5%</p> <p>experiments:</p> <p>distance between nouns and verbs</p> <p>attractor: last intervening nouns</p> <p>count of attractors</p> <p>relative clauses</p> <p>word representation learned the concept of singular and plural from scratch</p> <p>word-by-word activation visualization</p> <p>training obj</p> <p>verb inflection: have verb's singular form before verb(give cue to syntactic clause boundary</p> <p>grammaticality judge: (human rarely receive ungrammatical signals</p> <p>LM</p> <p>training only on hard dataset(with attractors)</p> <p>Agreement attraction errors in humans are much more common when the attractor is plural than when it is singular</p> <p>errors:</p> <p>noun-noun compounds</p> <p>verbs similar to plural nouns are mistaken as nouns: The ship that the player drives has a very high speed.</p> <p>limitation of the number prediction task, which jointly evaluates the model’s ability to identify the subject and its ability to assign the correct number to noun phrases</p> <h1 id="structural-supervision-improves-learning-of-non-local-grammatical-dependencies"><a href="#structural-supervision-improves-learning-of-non-local-grammatical-dependencies" class="header-anchor">#</a> Structural Supervision Improves Learning of Non-Local Grammatical Dependencies</h1> <p>Negative licensor: not none</p> <p>Negative Polarity Item: any ever</p> <p>filler-gap dependency</p> <p>RNNG</p> <p>word-synchronus beam search (Stern et al., 2017)</p> <p>Wh-Licensing Interaction</p> <p>Poverty of theStimulus Argument.</p> <p>purely data-driven learning is not powerful enough to explain the richness and uniformity of human grammars</p> <p>flashtext</p> <p><a href="https://github.com/vi3k6i5/flashtext" target="_blank" rel="noopener noreferrer">vi3k6i5/flashtext<svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></a></p> <h2 id="services-corps"><a href="#services-corps" class="header-anchor">#</a> services, corps</h2> <p>https://github.com/marcocor/tagme-python</p> <p>knowledge embedding TransE</p> <p>masked language model, next sent prediction as pre-training obj</p> <p>wit.ai</p> <p><a href="huggingface">write with transformer</a></p></div> <footer class="page-edit"><div class="edit-link"><a href="https://github.com/josherich/blog/edit/master/logs/nlp.md" target="_blank" rel="noopener noreferrer">在 GitHub 上编辑此页</a> <svg xmlns="http://www.w3.org/2000/svg" aria-hidden="true" x="0px" y="0px" viewBox="0 0 100 100" width="15" height="15" class="icon outbound"><path fill="currentColor" d="M18.8,85.1h56l0,0c2.2,0,4-1.8,4-4v-32h-8v28h-48v-48h28v-8h-32l0,0c-2.2,0-4,1.8-4,4v56C14.8,83.3,16.6,85.1,18.8,85.1z"></path> <polygon fill="currentColor" points="45.7,48.7 51.3,54.3 77.2,28.5 77.2,37.2 85.2,37.2 85.2,14.9 62.8,14.9 62.8,22.9 71.5,22.9"></polygon></svg></div> <!----></footer> <div class="page-nav"><p class="inner"><span class="prev">
      ←
      <a href="/logs/ml.html" class="prev">Machine Learning</a></span> <span class="next"><a href="/logs/numpy.html">Numpy</a>
      →
    </span></p></div> </main></div><div class="global-ui"><SWUpdatePopup></SWUpdatePopup><!----></div></div>
    <script src="/logs/assets/js/app.09a71387.js" defer></script><script src="/logs/assets/js/2.5fba0fc3.js" defer></script><script src="/logs/assets/js/21.f653a922.js" defer></script>
  </body>
</html>
