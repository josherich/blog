(window.webpackJsonp=window.webpackJsonp||[]).push([[21],{224:function(e,a,n){"use strict";n.r(a);var t=n(0),s=Object(t.a)({},(function(){var e=this,a=e.$createElement,n=e._self._c||a;return n("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[n("h2",{attrs:{id:"basic"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#basic"}},[e._v("#")]),e._v(" Basic")]),e._v(" "),n("h2",{attrs:{id:"matrix"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#matrix"}},[e._v("#")]),e._v(" Matrix")]),e._v(" "),n("ul",[n("li",[e._v("M[i,j], to access the item in the ith row and jth column;")]),e._v(" "),n("li",[e._v("M[i:j,:], to get the all the rows between the ith and j âˆ’ 1th;")]),e._v(" "),n("li",[e._v("M[:,i], to get the ith column of M;")])]),e._v(" "),n("p",[e._v("dot product")]),e._v(" "),n("p",[e._v("inner product")]),e._v(" "),n("p",[e._v("transpose")]),e._v(" "),n("p",[e._v("Identity Matrix")]),e._v(" "),n("h3",{attrs:{id:"np-api"}},[n("a",{staticClass:"header-anchor",attrs:{href:"#np-api"}},[e._v("#")]),e._v(" np api")]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v("np.repeat(n, 3)\nnp.arange(n)\nnp.full((3, 3), 1, dtype=bool)\nout = np.where(arr % 2 == 1, -1, arr)\nnp.reshape()\nnp.repeat(a, 3)\nnp.tile(a, 3)\nnp.concatenate\nnp.vstack\nnp.hstack\nnp.r_[a, b]\nnp.intersect1d(a, b)\n")])])]),n("ul",[n("li",[e._v("From 'a' remove all of 'b'")])]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v("np.setdiff1d(a,b)\n")])])]),n("ul",[n("li",[e._v("Get the positions where elements of a and b match")])]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v("np.where(a == b)\n\n")])])]),n("ul",[n("li",[e._v("get index meeting condition")])]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v("\n> Method 1\nindex = np.where((a >= 5) & (a <= 10))\na[index]\n\n> Method 2:\nindex = np.where(np.logical_and(a>=5, a<=10))\na[index]\n")])])]),n("ul",[n("li",[e._v("vectorize functions")])]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v("pair_max = np.vectorize(maxx, otypes=[float])\n")])])]),n("ul",[n("li",[e._v("reorder columns")])]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v("arr[:, [1,0,2]]\n")])])]),n("ul",[n("li",[e._v("reverse rows")])]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v("arr[::-1]\n")])])]),n("ul",[n("li",[e._v("generate random matrix distribution")])]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v("rand_arr = np.random.randint(low=5, high=10, size=(5,3)) + np.random.random((5,3))\n> or\nrand_arr = np.random.uniform(5,10, size=(5,3))\n")])])]),n("ul",[n("li",[e._v("pretty print, scientific notation")])]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v("np.set_printoptions(precision=3)\nnp.set_printoptions(suppress=True, precision=6)\nnp.set_printoptions(threshold=6)\nnp.set_printoptions(threshold=np.nan)\n")])])]),n("ul",[n("li",[e._v("keep text inact")])]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v("iris = np.genfromtxt(url, delimiter=',', dtype='object')\n")])])]),n("ul",[n("li",[e._v("use columns when import")])]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v("iris_2d = np.genfromtxt(url, delimiter=',', dtype='float', usecols=[0,1,2,3])\n")])])]),n("ul",[n("li",[e._v("normalize")])]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v("Smax, Smin = sepallength.max(), sepallength.min()\nS = (sepallength - Smin)/(Smax - Smin)\n")])])]),n("ul",[n("li",[e._v("softmax")])]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v('def softmax(x):\n  """Compute softmax values for each sets of scores in x.\n  https://stackoverflow.com/questions/34968722/how-to-implement-the-softmax-function-in-python"""\n  e_x = np.exp(x - np.max(x))\n  return e_x / e_x.sum(axis=0)\n')])])]),n("ul",[n("li",[e._v("percentile")])]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v("np.percentile(sepallength, q=[5, 95])\n")])])]),n("ul",[n("li",[e._v("insert random to random index")])]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v("> Method 1\ni, j = np.where(iris_2d)\n\ni, j contain the row numbers and column numbers of 600 elements of iris_x\nnp.random.seed(100)\niris_2d[np.random.choice((i), 20), np.random.choice((j), 20)] = np.nan\n\n> Method 2\nnp.random.seed(100)\niris_2d[np.random.randint(150, size=20), np.random.randint(4, size=20)] = np.nan\n")])])]),n("ul",[n("li",[e._v("Print first 10 rows")])]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v("print(iris_2d[:10])\n")])])]),n("ul",[n("li",[e._v("find nan value")])]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v('print("Number of missing values: \\n", np.isnan(iris_2d[:, 0]).sum())\nprint("Position of missing values: \\n", np.where(np.isnan(iris_2d[:, 0])))\n')])])]),n("ul",[n("li",[e._v("filter")])]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v("condition = (iris_2d[:, 2] > 1.5) & (iris_2d[:, 0] < 5.0)\niris_2d[condition]\n")])])]),n("ul",[n("li",[e._v("correlation")])]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v("np.corrcoef(iris[:, 0], iris[:, 2])[0, 1]\n\n> Solution 2\nfrom scipy.stats.stats import pearsonr\ncorr, p_value = pearsonr(iris[:, 0], iris[:, 2])\nprint(corr)\n")])])]),n("ul",[n("li",[e._v("find unique value")])]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v("# Extract the species column as an array\nspecies = np.array([row.tolist()[4] for row in iris])\n")])])]),n("ul",[n("li",[e._v("Get the unique values and the counts")])]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v("np.unique(species, return_counts=True)\n")])])]),n("ul",[n("li",[e._v("num to category")])]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v("> Bin petallength\npetal_length_bin = np.digitize(iris[:, 2].astype('float'), [0, 3, 5, 10])\n\n> Map it to respective category\nlabel_map = {1: 'small', 2: 'medium', 3: 'large', 4: np.nan}\npetal_length_cat = [label_map[x] for x in petal_length_bin]\n")])])]),n("ul",[n("li",[e._v("create new columns")])]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v("> Compute volume\nsepallength = iris_2d[:, 0].astype('float')\npetallength = iris_2d[:, 2].astype('float')\nvolume = (np.pi * petallength * (sepallength2))/3\n\n\n> Introduce new dimension to match iris_2d's\nvolume = volume[:, np.newaxis]\n\n# Add the new column\nout = np.hstack([iris_2d, volume])\n")])])]),n("ul",[n("li",[e._v("probabilistic sampling")])]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v("> Get the species column\nspecies = iris[:, 4]\n\n> Approach 1: Generate Probablistically\nnp.random.seed(100)\na = np.array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'])\nspecies_out = np.random.choice(a, 150, p=[0.5, 0.25, 0.25])\n\n# Approach 2: Probablistic Sampling (preferred)\nnp.random.seed(100)\nprobs = np.r_[np.linspace(0, 0.500, num=50), np.linspace(0.501, .750, num=50), np.linspace(.751, 1.0, num=50)]\nindex = np.searchsorted(probs, np.random.random(150))\nspecies_out = species[index]\nprint(np.unique(species_out, return_counts=True))\n")])])]),n("ul",[n("li",[e._v("get value grouped by another column")])]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v("> Get the species and petal length columns\npetal_len_setosa = iris[iris[:, 4] == b'Iris-setosa', [2]].astype('float')\n\n> Get the second last value\nnp.unique(np.sort(petal_len_setosa))[-2]\n")])])]),n("ul",[n("li",[e._v("sort by column")])]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v("print(iris[iris[:,0].argsort()][:20])\n")])])]),n("ul",[n("li",[e._v("find most freq")])]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v("> Solution:\nvals, counts = np.unique(iris[:, 3], return_counts=True)\nprint(vals[np.argmax(counts)])\n")])])]),n("ul",[n("li",[e._v("cutoff value")])]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v("> Solution 1: Using np.clip\nnp.clip(a, a_min=10, a_max=30)\n\n> Solution 2: Using np.where\nprint(np.where(a < 10, 10, np.where(a > 30, 30, a)))\n")])])]),n("ul",[n("li",[e._v("generate one-hot array")])]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v("def one_hot_encodings(arr):\n    uniqs = np.unique(arr)\n    out = np.zeros((arr.shape[0], uniqs.shape[0]))\n    for i, k in enumerate(arr):\n        out[i, k-1] = 1\n    return out\n")])])]),n("ul",[n("li",[e._v("one_hot_encodings(arr)")])]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v("array([[ 0.,  1.,  0.],\n       [ 0.,  0.,  1.],\n       [ 0.,  1.,  0.],\n       [ 0.,  1.,  0.],\n       [ 0.,  1.,  0.],\n       [ 1.,  0.,  0.]])\n\n> Method 2:\n(arr[:, None] == np.unique(arr)).view(np.int8)\n")])])]),n("ul",[n("li",[e._v("create category id")])]),e._v(" "),n("div",{staticClass:"language- extra-class"},[n("pre",{pre:!0,attrs:{class:"language-text"}},[n("code",[e._v("> Solution:\noutput = [np.argwhere(np.unique(species_small) == s).tolist()[0][0] for val in np.unique(species_small) for s in species_small[species_small==val]]\n\n> Solution: For Loop version\noutput = []\nuniqs = np.unique(species_small)\n\nfor val in uniqs:  # uniq values in group\n    for s in species_small[species_small==val]:  # each element in group\n        groupid = np.argwhere(uniqs == s).tolist()[0][0]  # groupid\n        output.append(groupid)\n\nprint(output)\n")])])])])}),[],!1,null,null,null);a.default=s.exports}}]);