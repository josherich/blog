(window.webpackJsonp=window.webpackJsonp||[]).push([[4],{207:function(e,a,t){e.exports=t.p+"assets/img/training.a9897041.png"},208:function(e,a,t){e.exports=t.p+"assets/img/sampling.5d5fd28a.png"},225:function(e,a,t){"use strict";t.r(a);var i=t(0),r=Object(i.a)({},(function(){var e=this,a=e.$createElement,i=e._self._c||a;return i("ContentSlotsDistributor",{attrs:{"slot-key":e.$parent.slotKey}},[i("h1",{attrs:{id:"paper-reading-notes"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#paper-reading-notes"}},[e._v("#")]),e._v(" paper reading notes")]),e._v(" "),i("h2",{attrs:{id:"pix2code-generate-code-from-a-graphical-user-interface-screenshot"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#pix2code-generate-code-from-a-graphical-user-interface-screenshot"}},[e._v("#")]),e._v(" pix2code: Generate Code from a Graphical User Interface Screenshot")]),e._v(" "),i("p",[e._v("similar to a image caption task")]),e._v(" "),i("p",[e._v("easy to create a lot of training data")]),e._v(" "),i("p",[e._v("use DSL as a smaller hypothsis space, one hot encode DSL tags")]),e._v(" "),i("p",[i("img",{attrs:{src:t(207),alt:"training"}}),e._v(" "),i("img",{attrs:{src:t(208),alt:"sampling"}})]),e._v(" "),i("h2",{attrs:{id:"semi-supervised-knowledge-transfer-for-deep-learning-from-private-training-data"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#semi-supervised-knowledge-transfer-for-deep-learning-from-private-training-data"}},[e._v("#")]),e._v(" Semi-supervised Knowledge Transfer for Deep Learning from Private Training Data")]),e._v(" "),i("p",[e._v("teachers trained on disjoint private data")]),e._v(" "),i("p",[e._v("students learn to predict by noisy voting from the teachers")]),e._v(" "),i("p",[e._v("model overfit and memorize data, attackers use hill-climbing from output probability, reveal real faces from dataset")]),e._v(" "),i("p",[e._v("strengthen this ensemble method by limited number of teacher votes, andy pick only topmost vote, after adding random noise")]),e._v(" "),i("p",[e._v("differential privacy")]),e._v(" "),i("p",[e._v("privacy loss")]),e._v(" "),i("p",[e._v("moment accountant")]),e._v(" "),i("h2",{attrs:{id:"making-neural-programming-architectures-generalize-via-recursion"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#making-neural-programming-architectures-generalize-via-recursion"}},[e._v("#")]),e._v(" Making Neural Programming Architectures Generalize via Recursion")]),e._v(" "),i("p",[e._v("$$ s_t = f_{enc}(e_t, a_t) $$\n$$ h_t = f_{lstm}(s_t, p_t, h_{t-1}) $$\n$$ r_t = f_{end}(h_t),  p_{t+1} = f_{prog}(h_t), a_{t+1} = f_{arg}(h_t) $$")]),e._v(" "),i("hr"),e._v(" "),i("ul",[i("li",[i("p",[e._v("$t$: time-step")])]),e._v(" "),i("li",[i("p",[e._v("$s_t$: state")])]),e._v(" "),i("li",[i("p",[e._v("$f_{enc}$: domain-specific encoder")])]),e._v(" "),i("li",[i("p",[e._v("$e_t$: environment slice")])]),e._v(" "),i("li",[i("p",[e._v("$a_t$: environment arguments")])]),e._v(" "),i("li",[i("p",[e._v("$f_{lstm}$: core module")])]),e._v(" "),i("li",[i("p",[e._v("$h_t$: hidden LSTM state")])]),e._v(" "),i("li",[i("p",[e._v("$f_{end}$: decode return probability $r_t$:")])])]),e._v(" "),i("h2",{attrs:{id:"understanding-deep-learning-requires-rethinkng-generization"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#understanding-deep-learning-requires-rethinkng-generization"}},[e._v("#")]),e._v(" Understanding Deep Learning requires rethinkng generization")]),e._v(" "),i("p",[e._v("regularization does not stop overfitting data with random labels")]),e._v(" "),i("p",[e._v("SGD has implicit regularization")]),e._v(" "),i("p",[e._v("capacity control")]),e._v(" "),i("p",[e._v("matrix factorization")]),e._v(" "),i("p",[e._v("parameters memorize the datasets")]),e._v(" "),i("p",[e._v("optimization on random labels")]),e._v(" "),i("p",[e._v("model fit on Gaussian noise")]),e._v(" "),i("h2",{attrs:{id:"using-morphological-knowledge-in-open-vocabulary-neural-language-models"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#using-morphological-knowledge-in-open-vocabulary-neural-language-models"}},[e._v("#")]),e._v(" Using Morphological Knowledge in Open-Vocabulary Neural Language Models")]),e._v(" "),i("p",[e._v("mixture model, with")]),e._v(" "),i("ul",[i("li",[i("p",[e._v("word model with finite vocabulary")])]),e._v(" "),i("li",[i("p",[e._v("char based model, dealing with UNK and subword structures")])]),e._v(" "),i("li",[i("p",[e._v("morphs model with max pooling on multiple morphes vectors, marginalize on multiple sequences of abstract morphemes")])])]),e._v(" "),i("p",[e._v("$$ p(w_i \\vert h_i) = \\sum_{m_i = 1}^M p(w_i, m_i \\vert h_i) $$\n$$ = \\sum_{m_i=1}^M p(m_i \\vert h_i)p(w_i \\vert h_i, m_i) $$")]),e._v(" "),i("p",[e._v("as seen above, models are weighted to compute the probability of $w_i$. The model assume that the selection of model i is conditionally independent of all models before it, given the sequence of word generated.")]),e._v(" "),i("p",[e._v("three word embeddings are concatednated and used as inputs, char embedding captures dative like Obame in Russian fro Obama; morphmes embeddings are max-pooled when different structures are find(say does can be decomposed as do+3-person+singular, or doe+plural)")]),e._v(" "),i("h3",{attrs:{id:"morphological-disambiguation"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#morphological-disambiguation"}},[e._v("#")]),e._v(" morphological disambiguation")]),e._v(" "),i("h2",{attrs:{id:"learning-to-map-sentences-to-logical-form-structured-classification-with-probabilistic-categorial-grammers"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#learning-to-map-sentences-to-logical-form-structured-classification-with-probabilistic-categorial-grammers"}},[e._v("#")]),e._v(" Learning to Map sentences to Logical Form: Structured Classification with Probabilistic Categorial Grammers")]),e._v(" "),i("ul",[i("li",[i("p",[e._v("constants: map entities, numbers, or functions to a value")])]),e._v(" "),i("li",[i("p",[e._v("logical connectors:")]),e._v(" "),i("ul",[i("li",[e._v("conjunction")]),e._v(" "),i("li",[e._v("disjunction")]),e._v(" "),i("li",[e._v("negative")]),e._v(" "),i("li",[e._v("implication")])])]),e._v(" "),i("li",[i("p",[e._v("quantification")]),e._v(" "),i("ul",[i("li",[e._v("universal, any")]),e._v(" "),i("li",[e._v("existential")]),e._v(" "),i("li",[e._v("count")]),e._v(" "),i("li",[e._v("argmax")]),e._v(" "),i("li",[e._v("argmin")]),e._v(" "),i("li",[e._v("definite l(lambda) reutrn the unique set for which the lambda exp is true")])])]),e._v(" "),i("li",[i("p",[e._v("lambda exp")])])]),e._v(" "),i("h3",{attrs:{id:"cgg-combinatory-categorial-grammer"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#cgg-combinatory-categorial-grammer"}},[e._v("#")]),e._v(" CGG(combinatory categorial grammer)")]),e._v(" "),i("ol",[i("li",[i("p",[e._v("functional application rules\na/b b = a\nb a\\b = a")])]),e._v(" "),i("li",[i("p",[e._v("functional application rules with semantics")])])]),e._v(" "),i("h3",{attrs:{id:"measuring-the-intrinsic-dimension-of-objective-landscapes"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#measuring-the-intrinsic-dimension-of-objective-landscapes"}},[e._v("#")]),e._v(" MEASURING THE INTRINSIC DIMENSION OF OBJECTIVE LANDSCAPES")]),e._v(" "),i("ol",[i("li",[e._v("theta^D = theta_0^D + P theta^d")]),e._v(" "),i("li",[e._v("invariant to model width and depth, if fc layers")]),e._v(" "),i("li",[e._v("90% performance as a threshold for intrinsic dimension")]),e._v(" "),i("li",[e._v("for RL task, performance is defined as max attained mean evaluation reward")]),e._v(" "),i("li",[e._v("750 dimension for MNIST, invariant for fc layer, variant for convolution layers(measured on shuffled labels)")]),e._v(" "),i("li",[e._v("dense / sparse / fastfood random matrix")])]),e._v(" "),i("h3",{attrs:{id:"ordered-neurons"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#ordered-neurons"}},[e._v("#")]),e._v(" ORDERED NEURONS")]),e._v(" "),i("p",[e._v("forget gate and input gate defined by binary sequence, trainable by counting")]),e._v(" "),i("p",[e._v("overlap of forget and input shows structure")]),e._v(" "),i("h3",{attrs:{id:"feudal"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#feudal"}},[e._v("#")]),e._v(" FeUdal")]),e._v(" "),i("p",[e._v("(1) transition policy gradient,")]),e._v(" "),i("p",[e._v("(2) directional cosine similarity rewards,")]),e._v(" "),i("p",[e._v("(3) goals specified with respect to a learned representation")]),e._v(" "),i("p",[e._v("(4) dilated RNN.")]),e._v(" "),i("h3",{attrs:{id:"simese-network"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#simese-network"}},[e._v("#")]),e._v(" Simese Network")]),e._v(" "),i("p",[e._v("learn feature from verification task(same or different images), then one-shot learning new category and test images, using max likelihood")]),e._v(" "),i("h3",{attrs:{id:"understanding-the-asymptotic-performance-of-model-based-rl-methods"}},[i("a",{staticClass:"header-anchor",attrs:{href:"#understanding-the-asymptotic-performance-of-model-based-rl-methods"}},[e._v("#")]),e._v(" UNDERSTANDING THE ASYMPTOTIC PERFORMANCE OF MODEL-BASED RL METHODS")]),e._v(" "),i("p",[e._v("optimal planning horizon can be over 100 steps")]),e._v(" "),i("p",[e._v("combining model-based and model-free")]),e._v(" "),i("ul",[i("li",[e._v("augment a model- free method with a model for faster learning")]),e._v(" "),i("li",[e._v("make up for the asymptotic deficiencies of a model-based method by transitioning to model-free.")])]),e._v(" "),i("p",[e._v("action-conditional predictor\nplan-conditional predictor")])])}),[],!1,null,null,null);a.default=r.exports}}]);